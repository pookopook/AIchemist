{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2회차 스터디\n",
    " - 오늘 목표: 1회차 복습, 데이터 분석과정, 데이터 불러오기, 시각화\n",
    "\n",
    "## 학습내용\n",
    "### 데이터 정규화와, 분석용 데이터셋\n",
    "#### 들어가며\n",
    " - Q. 데이터 분석에 있어 가장 많은 시간이 들어가는 작업은?\n",
    "   - 문제 정의\n",
    "   - 데이터 준비 (수집, 전처리, EDA)\n",
    "   - 모델링 (특징 선택, 모델 학습 및 평가)\n",
    "   - 결과 해석 및 적용 (시각화, 의사 결정, 배포)\n",
    "   - 모니터링 및 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터란?\n",
    " 0. 데이터의 정의\n",
    "    - 데이터(Data)란 현실 세계에서 관찰되거나 측정된 사실, 개념, 명령 등의 값을 의미합니다.\n",
    "    - DIKW 피라미드\n",
    "      - 데이터(Data) → 정보(Information) → 지식(Knowledge) → 지혜(Wisdom)\n",
    " 1. 일상(업무)에서 겪는 문제\n",
    "    - **Why? 분석이 안되는가?**\n",
    "    - 엑셀로 데이터를 분석하는 방법(vlookup, pivot)\n",
    "      1. vlookup - 두 테이블의 연결 -> 새로운 정보 생산\n",
    "      2. pivot - 데이터의 집계(**그룹**별, 합, 평균)\n",
    "    - 올바른 형태로 데이터를 만드는 방법 (DB 정규화)\n",
    "      1. 크로스탭 쿼리 정규화하는 간단한 예시\n",
    " 2. 엑셀에서 파이썬으로 넘어가기, why?\n",
    "    - 대량의 데이터(빅데이터)\n",
    "    - 여러 테이블의 연계\n",
    "    - 분석 ex. A/B test\n",
    "    - 예측 ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리\n",
    "라이브러리는 파이썬을 이용한 데이터 분석에 핵심입니다.  \n",
    "혹시, 엑셀 매크로를 들어보신 적 있으신가요?\n",
    "라이브러리를 초보자 입장에서 가장 이해하기 쉽게 설명드리면,  \n",
    "엑셀 매크로 집합?과 같은 거라고 생각하시면 됩니다.  \n",
    "\n",
    "매크로는 어떤 복잡한 작업을 쉽게 하려고 프로로그래밍해둔 것인데요.  \n",
    "라이브러리는 이러한 매크로를 한데 모아서 놔둔 것입니다.  \n",
    "\n",
    "따라서, 파이썬을 이용하여 데이터 분석을 한다는 것은,  \n",
    "분석용 라이브러리를 활용한다는 것과 동일합니다.\n",
    "\n",
    "아래에서 먼저 판다스라는 가장 대표적이고 기본적인 라이브러리를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 라이브러리 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 판다스는 데이터를 불러오는 가장 기본적인 라이브러리입니다.  \n",
    "### 코드설명\n",
    "  - import -> 라이브러리를 불러올 때때 사용합니다. 임포트-> 파이썬에서 사용할 수 있도록 라이브러리를 로드합니다.  \n",
    "  - pandas -> 라이브러리 이름입니다.  \n",
    "  - as -> 어떤 명칭으로 라이브러리를 부를 지 정합니다.  \n",
    "  - pd -> 판다스 라이브러리는 통상 pd로 지칭합니다. 마음대로 정할 수 있습니다.  \n",
    ">  ``` python\n",
    ">  import pandas as 나는내맘대로할래\n",
    ">  ```  \n",
    "  - 라고 해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as 나는내맘대로할래\n",
    "# 이렇게 해도 됩니다.\n",
    "# 하지만 보통 이렇게는 안하지요. 이유는 잠시 후 설명하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터프레임\n",
    "데이터프레임은 엑셀과 같이 테이블 형태로 된 데이터입니다.\n",
    "\n",
    "매출 데이터를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/매출데이터.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 코드설명\n",
    "  * df 라는 변수를 생성합니다. df는 데이터프레임의 약자이며, 판다쓰에서 흔히 사용하는 변수 이름입니다.\n",
    "    * 1차시에 배운 a = 1 과 비슷합니다. 다른 점은 df 에 정수(int)나 텍스트(str) 대신 데이터프레임(DataFrame)이 저장된 것 뿐입니다.\n",
    "  * pd - 아까 전에 import pandas as pd 를 실행했을 때 지정한 pd입니다. pandas 라는 라이브러리에서 어떤 함수를 호출하는 것입니다.\n",
    "  * read_csv 판다스 안에 read_csv라는 함수를 사용합니다. () 안의 내용은 read_csv가 요구하는 함수의 인자들이 들어갑니다.\n",
    "    * 'df = pd.read_csv(' 까지 타이핑하고 shift+tab을 누르면 어떤 내용이 들어가야하는 지 설명이 나옵니다.\n",
    "    * 공식 문서를 찾아보거나, gpt에게 'pd.read_csv에는 어떤 인자가 있는지 설명해줘' 라고 하면 상세하게 설명해줍니다.\n",
    "    * '매출데이터.csv' 를 입력함으로, df에 해당 매출 데이터를 불러오게 됩니다.\n",
    "  \n",
    "* ※ csv에 대하여\n",
    "  * csv는 데이터과학에서 흔히 사용하는 파일 형식입니다.\n",
    "  * 보통 ','로 구분됩니다.\n",
    "  * 판다스는 엑셀도 직접적으로 불러올 수 있습니다.\n",
    "  * read_excel('파일명') 하면 어떤 엑셀 데이터도 불러올 수 있습니다.\n",
    "\n",
    "* ※ 변수 이름 짓는 방법에 대한 참고\n",
    "  * df1, df2 로 하기도 하며, df_sales 등 다양한 이름으로 사용합니다. 변수 명명 방식은 자유롭게 할 수 있습니다.\n",
    "  * 보통 변수 이름에 이 변수의 타입(형식)을 알 수 있도록 df를 포함하도록 쓰기도 합니다.\n",
    "  * 공동작업을 하는 개발자들 사이에서는 변수 이름 짓기가 굉장히 중요한 문제입니다만, 우리는 초보자이고, 지금 당장 중요한 문제는 아닙니다. 편하게 지으면 됩니다!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "나는내맘대로할래.read_csv('매출데이터.csv') #이것도 되긴 해요...\n",
    "#이렇게 하면, 다른 사람들과 코드를 공유할때 문제가 됩니다.\n",
    "#코드를 복붙할 수가 없습니다.\n",
    "#컨벤션(전통, 관습?) 이 있는 as(알리아스)는 그대로 가는게 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터 내용 확인 - gpt로 만든 데이터입니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df 의 데이터 형식에 대하여\n",
    "- type(df) 를 해보면 'pandas.core.frame.DataFrame' 라는 것이 출력됨을 알 수 있습니다.\n",
    "- 1차시에 했던 'a=1, type(a)' 했을 때 'int'(정수)가 출력되는 것과는 다름을 알 수 있습니다.\n",
    "- df의 형식은 pandas에서 사용하는 DataFrame(이라고 이름지어진) 형식의 변수임을 알 수 있습니다.\n",
    "- 왜 데이터프레임일까요?\n",
    "  - 데이터를 표 형태로 담는 구조라서 프레임(틀) 이라는 말을 붙인 것 같아요\n",
    "  - 판다스 만든 개발자들의 네이밍 센스죠!\n",
    "- 여러분들도 여러분들만의 전용 라이브러리를 만든다면, 스스로 이름을 지을 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "print(type(a))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df의 기본 함수(메서드)\n",
    "* df라는 형식을 위해서 판다스에는 다양한 df용 함수들이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df 구조 확인\n",
    "* 아래 함수(메서드)들은 데이터 구조, 샘플을 확인하고자 할 때때 사용합니다.\n",
    "* 공부하다보면 이 함수들은 자연스럽게 외워집니다.\n",
    "\n",
    "| 메서드         | 설명                              |\n",
    "|----------------|-----------------------------------|\n",
    "| df.head(n)     | 앞에서 n행 확인 (기본값 5)        |\n",
    "| df.tail(n)     | 뒤에서 n행 확인                   |\n",
    "| df.info()      | 전체 구조 및 결측값 요약          |\n",
    "| df.describe()  | 수치형 열의 통계 요약              |\n",
    "| df.shape       | (행, 열) 튜플 반환                 |\n",
    "| df.columns     | 열 이름 확인                       |\n",
    "| df.index       | 인덱스 확인                        |\n",
    "| df.dtypes      | 열별 데이터 타입                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 언급된 함수(메서드)를 자유롭게 적어보세요. n에는 숫자를 넣어야합니다.\n",
    "# df.head(), df.head(10), df.tail(), df.tail(5), df.sample()\n",
    "# df.info(), df.describe(), df.shape()\n",
    "# df.columns, df.index, df.dtypes\n",
    "# 하고 type()으로 각 함수별로 출력값의 타입도 확인해보세요\n",
    "#df.메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### head 등\n",
    "* head, tail, sample 함수는 df의 실제 데이터 일부를 확인하는 함수입니다.\n",
    "* 빅데이터는 정말 크므로(몇백만~몇천만 혹은 그 이상, 실시간 업데이트 등) 엑셀 등 파일로 저장된 형태가 아닌 경우가 많습니다.\n",
    "* 일부 데이터를 확인하여 데이터가 의도대로 잘 불러와졌는지 확인하는 기능입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### info, describe, shape\n",
    "* 위 함수는 전체 데이터의 구조를 알아보는 기능입니다. 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### info는 데이터의 구조와, 형식, 갯수를 알려줍니다.\n",
    "* 컬럼 리스트, 결측값 수, 형식을 알 수 있습니다.\n",
    "  * 결측이란 누락된 데이터값을 의미합니다. 100% 채워진 데이터는 드뭅니다.\n",
    "* info를 통해 데이터를 확인해보면\n",
    "  * 매출 데이터는 총 200개의 데이터이며,\n",
    "  * 컬럼은 총 14개.\n",
    "  * 결측값이 일부 있으며,\n",
    "    * 일부 컬럼에서 2~4개 존재. -> 없는 데이터는 확인해보고 처리 방법을 고민해봐야합니다.\n",
    "    * 결측값 처리는 정말 중요합니다. 어떤 방법을 사용하느냐에 따라 이후 모델링에 지대한 영향을 줍니다.\n",
    "      * 실전 노하우와 통계적 노하우 등이 매우 많이 필요한 영역입니다. 상세한 내용은 이후에 천천히 공부해보겠습니다.\n",
    "  * 타입이 모두 object로 저장되어있습니다. object는 보통 텍스트이나, 별도의 자료형이 지정되어있지 않았다는 의미이기도 합니다.\n",
    "    * 따라서 자료형을 별도로 지정해줘야 할 필요가 있어 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shape는 데이터의 전체 크기(컬럼과, 데이터의 갯수)를 알려줍니다.\n",
    "* 보통 쉐입을 맞춘다고 표현합니다.\n",
    "* ai모델은 고정된 쉐이프(컬럼)를 입력으로 받아, 결과를 예측합니다.\n",
    "* 컬럼 갯수가 다르면 모델이 작동하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape   # (행의 수, 열의 수) 형태의 튜플을 반환합니다. shape은 df의 속성입니다. ()를 붙이지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### describe()\n",
    "* describe는 df의 수치형 자료에 대해 기본적인 통계량을 알려줍니다.\n",
    "* 평균, 최대 최소값 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# df.info() 에서 int, float형식의 데이터를 볼 수 있습니다.\n",
    "# 수량\t단가\t할인율\t매출액\t마진율\t마진액\n",
    "#df.describe(include='all') 하면 데이터 종류 구분 없이 조회 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* count : 결측을 제외한 데이터 갯수입니다.\n",
    "* mean : 평균값\n",
    "* std : 표준편차\n",
    "* min, max : 최소 최대\n",
    "* 25, 50, 75% : IQR이라고 하여, 분위수를 말합니다. 전체 분포에서 25%, 50%, 75% 순위에 있는 값입니다.\n",
    "  * 분위수랑? 데이터를 작은 값부터 정렬했을 때, 순서대로 일정 비율에 해당하는 값.\n",
    "  * 50% 가 평균 mean과 다른 이유\n",
    "    * mean은 전체를 더한 후 나눈 값으로 가상의 값입니다.\n",
    "    * 50% 는 중위수로, 200개의 값 중 100번쨰 값(중앙값)을 의미합니다.\n",
    "      * (데이터 갯수가 짝수이므로, 정확하게는 100번째와 101번쨰의 평균입니다.)\n",
    "    * 따라서 평균과 중위수가 다릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터의 구분\n",
    "[위키독스 01. 데이터 타입 참고](https://wikidocs.net/161040)\n",
    " * 데이터는 크게 다음과 같이 나눕니다.\n",
    "   * 텍스트 - 문장, 단어로 된 데이터\n",
    "   * 날짜 - yyyy-mm-dd로 된 형태의 데이터\n",
    "   * 범주 - 종류를 나눌 수 있는 데이터\n",
    "     * 명목형 - 순서가 없음 (성별, 매장명, 상품코드 등)\n",
    "     * 순서형 - 순서가 있음 (연령대)\n",
    "   * 숫자\n",
    "     * 이산형(정수형) - 판매량 등 (1개 2개 3개, 소수가 불가능)\n",
    "     * 연속형 - 할인율 등 (0.1, 0.25 등 소수가 가능)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 범주형 데이터의 표현\n",
    "* 범주형 데이터는 보통 코드로 나타냅니다.\n",
    "  * 연령대가 10대, 20대 30대 40대 라면 (범주형이고, 이산형(순서가 있음))\n",
    "    * 분석할 때 데이터는 1,2,3,4와 같이 숫자로 변환하곤 합니다.\n",
    "* 특별히 성별과 같이 2 종류만 있는 범주형 데이터는 True(1) / False(0) 로 표현 가능\n",
    "  * 이를 바이너리 코드 라고 하며, 0,1 만으로 충분히 표현 가능한 데이터를 말합니다.\n",
    "  * 남성 -> 0, 여성 -> 1 같이 표현할 수 있습니다. \n",
    "* 데이터 변환은 오늘은 하지 않고, 나중에 배워보도록 하겠습니다.\n",
    "  * 예습하시려면, '변수 인코딩'을 검색해보세요\n",
    "\n",
    "| 구분       | 설명                           | 예시            |\n",
    "|------------|--------------------------------|-----------------|\n",
    "| 명목형     | 순서 없음                      | 성별, 지역, 색상 |\n",
    "| 순서형     | 순서 있음                      | 학점(A,B,C), 연령대 |\n",
    "| 이산형     | 정수형 숫자, 개수 셀 수 있음   | 수량, 판매건수   |\n",
    "| 연속형     | 실수 포함, 무한히 쪼갤 수 있음 | 키, 할인율, 금액 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼 타입 바꾸기\n",
    "데이터를 적절하게 처리하기 위해서는 적절한 형식으로 변환해주어야합니다.\n",
    "다음과 같은 절차로 진행할 수 있습니다.\n",
    " 1. 컬럼과 타입을 먼저 확인, 어떻게 바꿔야 할 지 검토\n",
    " 2. 타입별로 컬럼을 변환합니다.\n",
    " 3. describe()로 결과를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 컬럼 타입 확인\n",
    "df.info()   # 14개 컬럼, 8 수량 제외 모두 object 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 검토결과, 대부분 잘 되어있으나\n",
    "  * 거래일자가 object로 날짜로 되어있지 않음\n",
    "  * 수량, 매출액, 마진액이 float로 소수점 단위로 되어있음 -> 정수여야 함\n",
    "  * 범주형 데이터로 취급 필요: 매장명, 상품코드, 상품명, 성별, 연령대, 결제수단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 컬럼 타입 지정(단일 컬럼 바꾸기)\n",
    "## '거래일자' 컬럼은 현재 object 형태입니다. date로 바꿔주겠습니다.\n",
    "df['거래일자'] = pd.to_datetime(df['거래일자'], errors='coerce')\n",
    "#결과확인\n",
    "df.info() #  0   거래일자    200 non-null    '''datetime64[ns]''' 로 나오면 정상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to_datetime 코드설명\n",
    "``` python\n",
    "df['거래일자'] = pd.to_datetime(df['거래일자'])\n",
    "```\n",
    "* 시리즈 (Series)\n",
    "  * df는 데이터프레임 전체이며, ['컬럼명']으로 데이터 프레임 중 일부 컬럼만을 불러올 수 있습니다.\n",
    "  * type(df['거래일자']) 을 해보면 'Series' 라는 데이터 타입을 볼 수 있습니다.\n",
    "  * 어떤 값만 한줄로 쭉 내려 적은 것으로, 1차원 데이터의 일종입니다.\n",
    "* 'df['거래일자'] =' 의 의미\n",
    "  * 'a = 1' 과 동일합니다. a 라는 상자에 1을 넣는 것입니다.\n",
    "  * df['거래일자'] 라는 상자에, = 이후의 데이터를 넣는 것입니다.\n",
    "  * 기존 데이터가 있긴 한데, 덮어씌우는 것으로 생각하면 됩니다.\n",
    "* pd.to_datetime: 판다스의 날짜 변환 함수\n",
    "  * 판다스pd의, to_datetime(날짜/시간으로) -> 말 그대로 날짜(date) 데이터로(to) 라는 의미입니다.\n",
    "    * to_datetime(df['거래일자']) 라는 표현을 통해\n",
    "    * 기존 텍스트로 저장된 df['거래일자']를,\n",
    "    * to_datetime을 통해 날짜 형식으로 변환하고\n",
    "    * = 을 통해 변환된 형식으로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 컬럼 타입 지정(여러 컬럼 한번에 바꾸기)\n",
    "\n",
    "int_cols = ['수량', '단가', '매출액', '마진액']\n",
    "for col in int_cols:\n",
    "    df[col] = df[col].round().astype('Int64')\n",
    "    # df[col] = pd.to_numeric(df[col], errors='coerce').round()  # 위 문장 대신 이거를 써도 되긴 합니다.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for문\n",
    "* for문은 반복 수행을 의미합니다.\n",
    "* 보통 파이썬에서 for문은 다음과 같이 사용합니다.\n",
    "``` python\n",
    "for '원소하나' in 리스트:\n",
    "    할일1\n",
    "    할일2.3.4.~~\n",
    "```\n",
    "  * 위에서 int_cols[~~~~] 로 리스트를 정해줬습니다.\n",
    "  * 리스트 안에 원소는 총 4개입니다.\n",
    "  * for 문으로 각 원소 하나에 대응하는 값을 불러오고,\n",
    "  * 그 값을 기준으로 할일을 수행합니다.\n",
    "  * '원소하나' 위치에 col 이라는 단어를 사용했습니다.\n",
    "    * col 이라는 어떤 하나의 컬럼명을 불러온 것입니다.\n",
    "##### 예제의 for문 흐름\n",
    "int_cols = ['수량', '단가', '매출액', '마진액']\n",
    "\n",
    "반복 실행 흐름:\n",
    "1. col = '수량'  → df['수량'] 처리\n",
    "2. col = '단가'  → df['단가'] 처리\n",
    "3. col = '매출액'  → df['매출액'] 처리\n",
    "4. col = '마진액'  → df['마진액'] 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 문에서 col의 의미\n",
    "## 리스트의 원소를 순서대로 반환함\n",
    "int_cols = ['수량', '단가', '매출액', '마진액']\n",
    "for col in int_cols:\n",
    "    print(f'작업시작 - {col}')\n",
    "    df[col] = df[col].astype('Int64')\n",
    "    # df[col] = pd.to_numeric(df[col], errors='coerce').round()  # 위 문장 대신 이거를 써도 되긴 합니다.\n",
    "    print(f'작업완료 - {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### astype()\n",
    "* 형식을 직접적으로 바꿔줍니다.\n",
    "* 가능한 형식\n",
    "* ### ✅ 자주 쓰는 `astype()` 타입들\n",
    "\n",
    "| 타입 문자열 / 객체     | 설명                                      |\n",
    "|------------------------|-------------------------------------------|\n",
    "| `'int'`, `'int64'`     | 일반 정수형 (결측치 있으면 에러 발생)     |\n",
    "| `'Int64'`              | Pandas 전용 **nullable 정수형** (결측치 허용) |\n",
    "| `'float'`, `'float64'` | 실수형                                     |\n",
    "| `'str'`                | 문자열                                     |\n",
    "| `'category'`           | 범주형 (메모리 절약 & 연산 속도 향상)      |\n",
    "| `'bool'`               | 불리언 (True/False)                        |\n",
    "| `'datetime64[ns]'`     | 날짜형                                     |\n",
    "| `'object'`             | 범용 파이썬 객체형 (보통 문자열로 사용됨) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to_numeric\n",
    "* to_date와 동일하게, numeric(숫자)로 변환하라는 의미입니다.\n",
    "* errors='coerce' : 는 혹시라도 문자열이 있으면, 이 데이터는 NaN(결측)으로 처리합니다. errors 구문을 없애고 처음부터 모든 코드를 다시 실행해보면 에러가 뜸을 알 수 있습니다.\n",
    "* round() 반올림합니다. round(1)은 소수점 한 자리로 맞춰줍니다. 숫자를 조정하여 원하는 자리수대로 맞출 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 변수 형변환\n",
    "``` python\n",
    ".astype('category')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['매장명', '상품코드', '상품명', '성별', '연령대', '결제수단']\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연령대에 대한 추가 형변환 처리\n",
    "## why? 연령대는 순서가 있음 10대 > 20대 > 30대 순\n",
    "\n",
    "# 카테고리 리스트 출력\n",
    "df['연령대'].cat.categories  # Index(['20대', '30대', '40대', '50대', '60대'], dtype='object')\n",
    "df['연령대'].cat.ordered  # 순서형 여부를 확인한다. True면 순서형이고 False면 순서가 아니므로 단순 범주형임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['연령대'] = df['연령대'].cat.as_ordered()\n",
    "df['연령대'].cat.ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.연령대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cat\n",
    "* .cat은 카테고리 컬럼에에 대해서만 작동하는 내부 함수.\n",
    "* .cat.으로 cat에 대한 다양한 설정이 가능하다. ※ cat.하고 tab키를 눌러보자.\n",
    "* cat.as_ordered()를 통해 범주형 데이터에 대해 순서가 있다고 지정하게 된 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')\n",
    "# 겉으로 보이는것은 이전과 크게 차이 없긴 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 필터링\n",
    "원하는 데이터만을 추출하여 보는 방법입니다.\n",
    "엑셀의 필터 기능과 유사합니다.\n",
    "여러 방법이 있으나 다음 두 가지 방법이 기본입니다.\n",
    "* df.iloc[n,m]  : n은 행, m은 열\n",
    "* df.loc[]\n",
    "\n",
    "| 항목        | .iloc                      | .loc                                 |\n",
    "|-------------|----------------------------|--------------------------------------|\n",
    "| 기준        | 인덱스 번호 (숫자) 기반     | 인덱스 이름 및 컬럼 이름 기반         |\n",
    "| 사용 형태   | `df.iloc[행, 열]`          | `df.loc[행이름, 컬럼이름]`           |\n",
    "| 예시        | `df.iloc[0, 2]`            | `df.loc[0, '상품명']`                |\n",
    "| 장점        | 빠르고 직관적임             | 컬럼명을 사용하므로 가독성이 높음      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df.iloc 방식의 필터링\n",
    "* iloc는 행과 열 숫자를 기반으로 값을 호출하는 함수입니다.\n",
    "* df.iloc[n,m] 과 같이 특정 위치의 값을 호출하거나,\n",
    "* df.iloc[n_start:n_end:n_step,m_start:m_end:m_step] 같이 n0~9 와 m0~9범위의 값을 호출할 수도 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]   # 0번 인덱스 값 가져오기 # series 형태로 출력됨, 1,2,3,4... 도 해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0:5]  # [: 로 전체 행, 0:5로 0~4번째까지의 컬럼 값을 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:100:5, 5:10] # 인덱스 기준으로 행은 0부터, 99까지 출력, 5개 단위로, 열은 5~9까지 5,6,7,8,9(5개 컬럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[150,9] # 행 인덱스 150번 데이터, 열 인덱스 9번 컬럼 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[150][9] # 동일한 결과이나, 위와는 작동방식이 조금 다름\n",
    "# type(df.iloc[150]) -> series 출력됨.\n",
    "# 시리즈 중, 9번째 값을 의미\n",
    "# `df.iloc[150][9]`은 시리즈를 먼저 추출한 후, 그 시리즈의 9번째 요소를 다시 찾는 방식입니다.  \n",
    "# 열 순서가 바뀌면 다른 열이 출력될 수 있으므로, `.iloc[150, 9]`처럼 한 번에 지정하는 것이 더 안전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iloc는.\n",
    ".iloc는 어떤 특정 단일 데이터 값을 출력하여, 이를 비교하는 방법으로 많이 활용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 인덱스를 지정하여 결과 출력\n",
    "idx = [1,3,5,7,9]\n",
    "df.iloc[idx,[5,13,3,5]]\n",
    "# idx에 포함된 행 중에\n",
    "# 열번호 5,13,3,5를 출력\n",
    "# 5가 두번 들어갔는데,동일 컬럼을 두번 넣는것도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc 방식의 필터링\n",
    "* .loc[n, [컬럼 리스트]] 형태로 활용하거나,  \n",
    "* .loc[조건] 형태로 활용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:10:2,'매장명':'수량']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[30:10:-5, ['상품코드','고객ID','연령대']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조건에 의한 필터링\n",
    "\n",
    "| 연산자 | 의미             | 예시                        |\n",
    "|--------|------------------|-----------------------------|\n",
    "| `==`   | 같다             | `df['성별'] == '남성'`     |\n",
    "| `!=`   | 같지 않다        | `df['연령대'] != '30대'`   |\n",
    "| `>`    | 크다             | `df['단가'] > 3000`         |\n",
    "| `<`    | 작다             | `df['수량'] < 5`            |\n",
    "| `&`    | 그리고 (and)     | `(조건1) & (조건2)`        |\n",
    "| `|`    | 또는 (or)        | `(조건1) | (조건2)`        |\n",
    "| `()`   | 우선순위 지정    | 꼭 괄호로 감싸야 오류 없음 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['수량'] >= 5].shape\n",
    "# 판매수량 5개 이상인 데이터는? 37개\n",
    "# 조건 연산자는 1차수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['수량'] >= 5) & (df['단가'] < 3000)].shape\n",
    "# 판매수량 5개 이상이면서, 단가 3000원 미만인 데이터는? 12개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['수량'] >= 5) & (df['단가'] >= 2000) & (df['단가'] < 3000)].shape\n",
    "# 판매수량 5개 이상이면서, 단가 2천원 이상, 3천원 미만인 데이터는? 5개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건이 점점 복잡해지면 이렇게 할 수 있습니다.\n",
    "con1 = df['할인율'] == 0.1\n",
    "con2 = df['상품명'] == '닭가슴살팩'\n",
    "con3 = df['단가'] >= 3000\n",
    "df.loc[con1 & con2 & con3]  # 3 조건을 모두 만족"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con3 = df['단가'] >= 5000  # con3만 조건 수정\n",
    "df.loc[con1 & (con2 | con3)] # 할인율이 0.1이면서 → (닭가슴살팩이거나 단가가 5천원 이상) 인 조건"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 마진률 이하이면서, 마진액이 1,000원 미만인 데이터 수\n",
    "mean_margin = df.마진율.mean()\n",
    "con4 = df['마진율'] <= mean_margin\n",
    "con5 = df['마진액'] <= 1000\n",
    "# .mean()으로 평균을 구합니다. \n",
    "# df['마진율'] 을 df.마진율 로 쓸수도 있습니다만, df['컬럼명']을 권장합니다.\n",
    "df.loc[con4 & con5].shape   # (30, 14) -> 30개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (파생변수)새로운 컬럼 생성\n",
    "* 파생변수 라고 합니다. 기존의 데이터들로부터, 새로운 데이터(정보)를 만들 수 있습니다.\n",
    "* 보통은 숫자 데이터의 조합으로 만들어냅니다.\n",
    "* df[새로운_변수명] = df[기존1] * df[기존2] 방식입니다.\n",
    "  * 아주 간단합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# 데이터 기준으로 총 매출액은 수량*단가에서 할인금액을 제외한 금액입니다.\n",
    "# 판매가 = 수량*단가 (할인 전 금액)\n",
    "# 할인금액 = 판매가 - 매출액 을 만들어봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사례1 - 판매가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['판매가'] = df['수량'] * df['단가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  ## 판매가 추가 확인."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사례 2 - 할인금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['할인금액'] = df['판매가'] - df['매출액']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파생변수를 통한 데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할인금액 기준 75%분위수 이상, 연령대 30대 이하, 매출액 1만원 미만 데이터를 출력\n",
    "q3 = df['할인금액'].quantile(0.75)\n",
    "con6 = df['할인금액'] >= q3\n",
    "con7 = df['연령대'] <= '30대'\n",
    "con8 = df['매출액'] < 10000\n",
    "df.loc[con6 & con7 & con8]\n",
    "# 조건 요약:\n",
    "# - 할인금액이 상위 25%에 해당하면서 (`con6`)\n",
    "# - 연령대가 30대 이하이며 (`con7`)\n",
    "# - 매출액이 1만원 미만인 (`con8`) 경우만 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사례3 - 그룹별 편차\n",
    "* 상황\n",
    "  * 매장명,성별 그룹별로 매출액 평균과, 각 거래의 매출액과 차이를 구한 '편차' 컬럼을 구해보자.\n",
    "  * (응용문제) 아직은 어려우실수 있습니다. groupby는 다음 차수에 자세하게 설명드리겠습니다.\n",
    "  * 일단 맛보기로 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 평균을 구합니다.\n",
    "group_avg = df.groupby(['매장명','성별'])['매출액'].mean().round().astype('int64')\n",
    "# 경고는 무시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 코드설명\n",
    "* group_avg = 블라블라블라.  -> a = 1 입니다. group_avg라는 변수에, 다음 내용을 넣는겁니다.\n",
    "* df.groupby(['그룹기준1','그룹기준2','그룹기준3'...])  -> 기준별로 데이터의 그룹을 만들어줍니다.\n",
    "* ['매출액'] -> 그룹을 지은 후, 매출액을 추출,\n",
    "* .mean() 평균을 구합니다. (그룹별로 구분하여 평균을 구함)\n",
    "* .round() 1자리로 반올림, .astype('int64') 정수 타입으로 형식 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_avg  # 그룹별 평균을 구했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 출력결과를 보면 ***Name:매출액*** 으로 적혀있습니다.  \n",
    "이 series의 이름이 매출액이라는 의미지요.  \n",
    "이대로 사용하면, 기존 df에 있는 '매출액'과 이름이 같아 충돌됩니다.  \n",
    "이것을 바꿔주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_avg.rename('그룹별평균_tmp', inplace=True)\n",
    "# rename으로 이름을 바꿔줍니다, _tmp로 임시로 저장하는 것으로 처리해줍니다.\n",
    "# inplace=True를 통해, group_avg 자체를 바꿔줍니다. a = 1 효과\n",
    "# inplace=True를 사용하지 않으면, 이렇게 해야합니다.\n",
    "# -> group_avg = group_avg.rename('그룹평균')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_avg #이름이 바뀌었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 평균을 기존 df에 병합(엑셀의 vlookup)\n",
    "df['그룹별평균'] = df.merge(group_avg, on=['매장명', '성별'])['그룹별평균_tmp']\n",
    "df.head(5)  #그룹별 평균이 붙었는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .merge() 코드설명\n",
    "* .merge는 두 테이블을 하나로 합치는 기능입니다. 엑셀의 vlookup과 유사합니다.\n",
    "  * 첫시간에 vlookup의 본질에 대해 설명드렸습니다. 두 테이블의 정보를 합치는 의미가 있다고 말씀드렸습니다.\n",
    "  * ***df***.merge(***group_avg***) 에서 볼 수 있듯. df 데이터를 기준으로, group_avg 데이터를 합칩니다.\n",
    "* on 은 데이터를 가져올 때의 기준입니다.\n",
    "  * 여기서는 group_avg는 매장명, 성별을 기준으로 구한 집계값을 넣어주는 것입니다.\n",
    "* ***df.merge(group_avg, on=['매장명', '성별'])*** 자체가 하나의 큰 df입니다.\n",
    "  * type(df.merge(group_avg, on=['매장명', '성별'])) 으로 확인해보세요\n",
    "  * df이름['컬럼이름']으로 하나의 컬럼만 시리즈로 불러올 수 있습니다.\n",
    "* df['그룹별평균'] = df.merge(~~~~~)['그룹별평균_tmp']\n",
    "  * df의 그룹별평균으로, df.merge한 또 하나의 df의 임시 컬럼임 그룹별평균_tmp를 저장해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편차를 구하기 매출액 - 평균\n",
    "df['편차'] = df['매출액'] - df['그룹별평균']\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['편차'].plot.hist()  # 차트까지 그려볼 수 있다. 차트는 나중에 자세히 배워볼께요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✏️ 미니 실습\n",
    "1. 본인이 알고 있는 CSV 파일을 불러와보세요.\n",
    "2. `df.info()`, `df.describe()` 를 이용해 데이터를 탐색해보세요.\n",
    "3. `type(df)` 를 출력해보고, 어떤 형식인지 이해해보세요.\n",
    "4. `df.shape`와 `type(df)`의 차이도 함께 확인해보세요.\n",
    "\n",
    "### ✍️ 타입과 for문\n",
    "1. df['할인율'] 컬럼이 object 타입이라고 가정할 때, 실수형으로 변환하는 코드를 작성해보세요.\n",
    "2. '성별', '연령대' 컬럼이 범주형 데이터라고 했을 때, 그 이유는 무엇인가요?\n",
    "3. 아래 코드를 설명해보세요.\n",
    "```python\n",
    "for col in ['단가', '마진액']:\n",
    "    df[col] = df[col].astype('Int64')\n",
    "```\n",
    "### ✍️ 필터링 연습하기\n",
    "1. df에서 매장명이 '명동점'인 데이터만 출력해보세요.\n",
    "2. df에서 인덱스 50~100번 행의 '상품명', '매출액' 컬럼만 출력해보세요.\n",
    "3. df에서 인덱스 50~100번 행 중 '할인율'이 0.2 이상인 데이터를 필터링하세요.\n",
    "\n",
    "### ✅ 다중 조건 필터링\n",
    "1. 수량이 3 이상이고, 단가가 2000 미만인 데이터만 필터링하세요.\n",
    "2. 다음 조건에 맞는 데이터를 추출해보세요:\n",
    "   - 할인율은 0.2\n",
    "   - 결제수단은 '카드'\n",
    "   - 성별은 '여성' 또는 단가 ≥ 5000원\n",
    "\n",
    "### 파생변수 만들기\n",
    "1. 분기(1~4분기) 파생변수를 만들어보세요.\n",
    "2. 1분기 매출액의 합은?\n",
    "2. 할인금액이 가장 많은 분기는?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
